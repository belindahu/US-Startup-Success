---
title: "Final Project"
author: "Belinda Hu"
date: "4/25/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(tidyselect)
library(readr)
library(tidycensus)
library(gt)
library(scales)
library(ggplot2)
library(sf)
library(date)
library(gganimate)
library(skimr)
library(broom)

census_api_key("03bf7eeb14e29c5d6fd4073fce357ba84f0017cc")

```

```{r load crunchbase data, echo = FALSE, message = FALSE}

# loading in companies and deselecting irrelevant rows.
# using message =  FALSE to get rid of parsing failure

companies <- read_csv("raw-data/companies.csv",
                      col_types = cols(
  permalink = col_character(),
  name = col_character(),
  homepage_url = col_character(),
  category_list = col_character(),
  funding_total_usd = col_character(),
  status = col_character(),
  country_code = col_character(),
  state_code = col_character(),
  region = col_character(),
  city = col_character(),
  funding_rounds = col_double(),
  founded_at = col_date(format = ""),
  first_funding_at = col_date(format = ""),
  last_funding_at = col_date(format = "")
)) %>% 
  select(-permalink, -homepage_url, -count, -formula) %>% 
  filter(country_code == "USA")

# loading in funding, added in a funding year column for future purposes,
# changed $ to be in terms of ten millions

investments <- read_csv("raw-data/investments.csv") %>% 
  select(-company_permalink, -investor_permalink, -funding_round_permalink) %>% 
  mutate(funding_year = as.numeric(format(funded_at, "%Y"))) %>% 
  mutate(raised_amount_usd = raised_amount_usd/1000000)

investments %>% filter(funding_year < 1980) %>% filter(company_category_list == "Enterprise Software")

```

# Exploratory Analysis of Data

## Types of startups by state 

```{r tidy, echo = FALSE}

# need to unlist category_code using separate and regex expressions separated
# category list into separate columns, calculated the max number of columns in
# excel. then used pivot_longer to lengthen the table to make calculating much
# easier later
 
companies2 <- companies %>% 
 separate(data = ., 
           col = category_list, 
           into = c("cat_1", "cat_2", "cat_3","cat_4", "cat_5", "cat_6", "cat_7", "cat_8", "cat_9", "cat_10", "cat_11", "cat_12", "cat_13", "cat_14", "cat_15", "cat_16", "cat_17", "cat_18", "cat_19", "cat_20", "cat_21", "cat_22", "cat_23", "cat_24", "cat_25", "cat_26", "cat_27", "cat_28", "cat_29", "cat_30", "cat_31", "cat_32", "cat_33", "cat_34", "cat_35", "cat_36", "cat_37", "cat_38", "cat_39", "cat_40", "cat_41", "cat_42", "cat_43", "cat_44"),
           sep = "([\\|])", 
           extra = "merge", 
           fill = "right") %>% 
  pivot_longer(
    cols = starts_with("cat_"),
    names_to = "cat_num",
    names_prefix = "cat_",
    values_to = "category",
    values_drop_na = TRUE
 )

```

```{r top types table, echo = FALSE}

# need to convert state abbr to name:
# https://worldpopulationreview.com/states/state-abbreviations/

stateabbr <- read_csv("raw-data/stateabbr.csv")%>% 
  select(State, Code)

```

# Visualizing Investments

## Total Investment

```{r investments over the year, echo = FALSE}

# using na.rm = T so that R discounts NA's. used a logged scale to make it
# relatively easy to read. need to fix graph scaling though

log_over_time <- investments %>% 
  filter(company_country_code == "USA") %>% 
  group_by(funding_year) %>% 
  summarise(total = sum(raised_amount_usd, na.rm = T)) %>% 
  ggplot(., aes(x = funding_year, y = total/1000)) +
  geom_point() +
  geom_line() +
  theme_classic() +
  scale_y_log10(labels = comma) +
  labs(title = "Total Investments Over Time",
       subtitle = "Data from Dec. 4, 2015 Crunchbase Data Report",
       x = "Year", 
       y = "Billion USD") +
  transition_reveal(funding_year) 

# saving to shiny to call in shiny app

anim_save("log_over_time.gif", log_over_time, path = "Startups")

```

# Investments by Industry

```{r data wrangling, echo = FALSE}

# did some analysis in excel to determine max number of categories is 23.
# grouped by funding year and category, sorted for top 5 funded startup types.

investments2 <- investments %>% 
  filter(! is.na(raised_amount_usd)) %>% 
  separate(data = ., 
           col = company_category_list, 
           into = c("cat_1", "cat_2", "cat_3","cat_4", "cat_5", "cat_6", "cat_7", "cat_8", "cat_9", "cat_10", "cat_11", "cat_12", "cat_13", "cat_14", "cat_15", "cat_16", "cat_17", "cat_18", "cat_19", "cat_20", "cat_21", "cat_22", "cat_23"),
           sep = "([\\|])", 
           extra = "merge", 
           fill = "right") %>% 
  pivot_longer(
    cols = starts_with("cat_"),
    names_to = "cat_num",
    names_prefix = "cat_",
    values_to = "category",
    values_drop_na = TRUE
 ) %>% 
  filter(company_country_code == "USA")

# finding top ten funded categories, using this as a list to filter within
# top_funded dataset

top_ten <- investments2 %>% 
  group_by(category) %>% 
  summarise(total = sum(raised_amount_usd, na.rm = T)) %>% 
  mutate(total = round(total/1000, digits = 2)) %>% 
  arrange(desc(total)) %>% 
  head(9)

# writing this to shiny to plot top industries
write_rds(top_ten, path = "Shiny/top_ten.rds")

# creating a gt table of top ten industries (there's really only 9 oops)
# this is copied into shiny

top_ten_gt <- top_ten %>%
  gt() %>%
  tab_header(
    title = "Top 9 US Startup Industries by Total Funding",
    subtitle = "1979-2015"
  ) %>%
  cols_label(
    category = "Industry",
    total = "Total Funding (Billion USD)"
  ) %>%
  cols_align(
    "center"
  ) %>%
  tab_footnote(
    footnote = "Data from Dec. 4, 2015 Crunchbase Data Report",
    locations = cells_title("title"))
  
```

## Tracking Funding Over Time

``` {r funding over time, echo = FALSE}

# creating a datasset that only includes top 9 industries

nine_industries <- investments2 %>% 
  filter(category %in% top_ten$category[1:9]) %>% 
  mutate(category = as.factor(category)) 

# saving as rds to plot best cities - to be used for cities graphs

write_rds(nine_industries, path = "Shiny/nine_industries.rds")

#  creating another dataset to track funding over time

ind_funding_over_time <- nine_industries %>% 
  group_by(category, funding_year) %>% 
  mutate(total = sum(raised_amount_usd, na.rm = T)) %>% 
  mutate(total = round(total/1000, digits = 2)) 

# writing this into shiny as well

write_rds(ind_funding_over_time, path = "Shiny/ind_funding_over_time.rds")

# plotting funding over time with log scale, faceted by category/industry

log_top_funded <- ind_funding_over_time %>%
  ggplot(., aes(x = funding_year, y = total, color = category)) +
  facet_wrap(~category) +
  geom_point(show.legend = FALSE) +
  geom_line(show.legend = FALSE) +
  labs(title = "US Investments Over Time for Top-Funded Industries, 1979 - 2015",
       subtitle = "Using a normal y scale",
       x = "Year",
       y = "Funding (Billion USD)") + 
  scale_y_log10() 
  
# plotting funding over time regular y axis scale, faceted by category/industry

reg_top_funded <- ind_funding_over_time %>%
  ggplot(., aes(x = funding_year, y = total, color = category)) +
  facet_wrap(~category) +
  geom_point(show.legend = FALSE) +
  geom_line(show.legend = FALSE) +
  labs(title = "US Investments Over Time for Top-Funded Industries, 1979 - 2015",
       subtitle = "Using a normal y scale",
       x = "Year",
       y = "Funding (Billion USD)")

# adding animations to both

reg_top_funded + transition_reveal(funding_year)
log_top_funded + transition_reveal(funding_year)

```

# Looking into trends 

## top cities for funding by top 9-funded industries

```{r}

# saving from repetitive coding my using dynamic plotting in shiny

plot <- nine_industries %>% 
  filter(category == input$industries) %>%
  filter(! is.na(company_city)) %>% 
  filter(company_country_code == "USA") %>% 
  select(raised_amount_usd, company_city, company_state_code) %>% 
  mutate(company_city = paste(company_city, sep = ", ", company_state_code)) %>% 
  group_by(company_city) %>% 
  summarise(total = sum(raised_amount_usd)) %>% 
  arrange(desc(total)) %>% 
  head(10) %>% 
  ggplot(., aes(x = total/1000, y = fct_reorder(company_city, total))) +
  geom_bar(stat = "identity") +
  theme_minimal() +
  labs(x = "Total Funding (Billion USD)",
       y = "Company Cities",
       caption = "Based off of Company Location, until 2015")
        
plot

# this would be an example if I plotted individually per industry. would just
# change the filter function

biotech_cities <- nine_industries %>%
  filter(category == "Biotechnology") %>%
  filter(! is.na(company_city)) %>%
  filter(company_country_code == "USA") %>%
  select(raised_amount_usd, company_city, company_state_code) %>%
  mutate(company_city = paste(company_city, sep = ", ", company_state_code)) %>%
  group_by(company_city) %>%
  summarise(total = sum(raised_amount_usd)) %>%
  arrange(desc(total)) %>%
  head(10) %>%
  ggplot(., aes(x = total/1000, y = fct_reorder(company_city, total))) +
  geom_bar(stat = "identity") +
  theme_minimal() +
  labs(title = "Top 10 US Cities for Biotechnology Funding, until 2015",
       subtitle = "Based off of company location",
       x = "Total Funding (Billion USD)",
       y = "Company Cities")

```

# How education impacts whether a startup is founded

## Higher Education

```{r CA, echo = FALSE}

# obtaining hs education pop in each state, bachelor's pop, and income. 2015 acs
# refers to last five years, so I will be using startup data from 2011-2015.

hs_education <- get_acs(geography = "state",
                        variables = c("B15003_017"),
                        year = 2015,
                        survey = "acs5", 
                        summary_var = "B15002_001") %>% 
  select(-GEOID) 

ba_education <- get_acs(geography = "state",
                        variables = "B15003_022",
                        year = 2015,
                        survey = "acs5",
                        summary_var = "B15002_001") %>% 
  select(-GEOID)

# downloading higher institution data from:
# https://hifld-geoplatform.opendata.arcgis.com/datasets/colleges-and-universities/data.
# Cleaned up in excel first to make it easier to read in.

colleges <- read_csv("raw-data/Colleges_and_Universities.csv", 
                     col_types = cols(
  NAME = col_character(),
  ADDRESS = col_character(),
  CITY = col_character(),
  STATE = col_character(),
  ZIP = col_double(),
  POPULATION = col_double(),
  COUNTY = col_character(),
  COUNTYFIPS = col_character(),
  COUNTRY = col_character(),
  LATITUDE = col_double(),
  LONGITUDE = col_double()
))

# organizing college dataset by adding in abbreviations to make  joining with
# exisitng data easier

full_colleges <- colleges %>% 
  group_by(STATE) %>% 
  count() %>% 
  rename(inst_count = "n") %>% 
  full_join(companies_per_state, by = c("STATE" = "state_code")) %>% 
  filter(! is.na(STATE)) %>% 
  rename(startup_count = "n")

# writing data to shiny

write_rds(full_colleges, path = "Shiny/full_colleges.rds")

# creating a new dataset without outliers by removing top and bottom 5
# percentiles

y <- quantile(full_colleges$startup_count,c(0.05,0.95), na.rm  = TRUE)
x <- quantile(full_colleges$inst_count,c(0.05,0.95), na.rm  = TRUE)

clean_full_colleges <- full_colleges %>% 
  filter(startup_count >= y[1] & startup_count <= y[2]) %>% 
  filter(inst_count >= x[1] & inst_count <= x[2])

# writing into Shiny

write_rds(clean_full_colleges, path = "Shiny/clean_full_colleges.rds")

# creating the regression

inst_model <- full_colleges %>% 
  lm(startup_count ~ inst_count, data = .) %>% 
  tidy(conf.int = TRUE) %>% 
  select(term, estimate, conf.low, conf.high) %>%
  mutate(estimate = round(estimate, digits = 3), 
         conf.low = round(conf.low, digits = 3), 
         conf.high = round(conf.high, digits = 3))

#gt table

inst_gt <- inst_model %>% 
  gt() %>% 
  tab_header(
    title = "Effect of Number of Higher Level Institutions on Number of New Startups, 2011-2015
"
  ) %>% 
   cols_label(
    term = "Variable",
    estimate = "Estimate",
    conf.low = "Lower bound",
    conf.high = "Upper bound"
  ) %>% 
  cols_align(
    "center"
  ) %>% 
  tab_footnote(
    footnote = "College and University Data from US Dept. of Homeland Security",
    locations = cells_title("title"))

# model without outliers, using clean_full_college

clean_inst_model <- clean_full_colleges %>% 
  lm(startup_count ~ inst_count, data = .) %>% 
  tidy(conf.int = TRUE) %>% 
  select(term, estimate, conf.low, conf.high) %>%
  mutate(estimate = round(estimate, digits = 3), 
         conf.low = round(conf.low, digits = 3), 
         conf.high = round(conf.high, digits = 3))

#gt table

clean_inst_gt <- clean_inst_model %>% 
  gt() %>% 
  tab_header(
    title = "Effect of Number of Higher Level Institutions on Number of New Startups, 2011-2015",
    subtitle = "Removing Outliers below 5th and above 95th Percentile"
  ) %>% 
   cols_label(
    term = "Variable",
    estimate = "Estimate",
    conf.low = "Lower bound",
    conf.high = "Upper bound"
  ) %>% 
  cols_align(
    "center"
  )

clean_inst_gt

```

## making a ggplot of regressions

```{r visualizing reg, echo = FALSE}

# creating a ggplot of the regression that yielded more results.  adding in a
# line for outliers

reg_plot <- full_colleges %>% 
  na.omit() %>% 
  ggplot(., aes(x = inst_count, y = startup_count)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Relationship between number of higher instituions and number of new startups",
       subtitle = "2011-2015, each point represents a state",
       x = "Number of Higher Institutions",
       y = "Number of Startups Founded") +
  geom_smooth(data = clean_full_colleges, method = "lm", se = FALSE, color = "red")

reg_plot

# saving as png

ggsave("reg_plot.png", plot = reg_plot, path = "Shiny")

```


next steps: 
- make a map of most common type of startup by state
- top 3 types of startups by state
- make this interactive

todo:
- investments over time: fix y axis
- investments over time by industry: fix y axis
- worldwide vs. in the US
- total funding in cities vs. income
  - do this by industry
- choose top 4 cities
- reformat axes
- add in states
